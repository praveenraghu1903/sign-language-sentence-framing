# sign-language-sentence-framing
"A project for recognizing hand gestures and framing sentences using sign language. Combines TensorFlow, MediaPipe, and OpenMP for gesture recognition and AI chatbot integration for generating context-aware sentences."

Sign Language Sentence Framing
Overview  
This project enables real-time recognition of hand gestures to frame sentences in sign language. It leverages **TensorFlow**, **MediaPipe**, and **OpenMP** for gesture recognition and integrates an **AI chatbot** to provide context-aware sentence generation.  

Features  
- **Gesture Recognition**: Detects and classifies hand signs in real time.  
- **Sentence Framing**: Converts recognized gestures into meaningful sentences.  
- **AI Chatbot Integration**: Enhances sentence context and provides intelligent responses.  
- **Efficient Processing**: Utilizes OpenMP for optimized performance on multi-core systems.  

Technologies Used  
- **TensorFlow**: For training and deploying gesture recognition models.  
- **MediaPipe**: For hand tracking and keypoint extraction.  
- **OpenMP**: For parallel processing to speed up computation.  
- **Python**: Primary programming language for integration and execution.  

**INSTALLATION**
just upload the folder in vscode and run imp.py to make dataset for sign language ( alphabets a-z) then run dataset.py. resolve errors by installing requires liberaries. then run classifier and at last main file. Train the ai chatbot for more sentences in knowledge.json.
